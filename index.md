---
title: Scientific Foundation Models
layout: home
---

## Why Scientific Foundation Models?
Foundation models refers to large machine learning models trained on vast diverse datasets and generalizable to on a wide range of prediction or generation tasks. In contrast to conventional machine learning models, which are optimized to perform a single task, a foundation model serves as a “prior” or “foundation” upon which other models can be built. This prior is learnt using self-supervised pre-training strategies which leverage unlabeled datasets. The representations learnt by the pre-trained foundation model can then be applied to a wide range of downstream tasks, after finetuning a limited number of the model's parameters on a smaller labelled dataset. This ability to leverage unlabelled data is particularly useful in scientific domains where the scope of supervised machine learning methods is limited to due the scarcity of labelled data and the high cost of experiments or computational simulations to needed label datasets.

